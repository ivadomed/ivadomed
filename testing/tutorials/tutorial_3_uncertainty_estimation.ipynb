{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TOFLk8iPrzkf"
   },
   "source": [
    "### Ivadomed Tutorial 3: **Uncertainty Estimation**\n",
    "\n",
    "This tutorial shows how to estimate uncertainty measures (aleatoric and epistemic) on the model's predictions. These uncertainty measures are already implemented in `ivadomed` and are detailed in [Technical features](https://ivadomed.org/technical_features.html#uncertainty-measures).\n",
    "\n",
    "‚ö†Ô∏è Before getting started, please ensure that you: \n",
    "\n",
    "1.   Are connected to the GPU. You can do this by doing the following from the task bar on the top: `Runtime` $\\to$ `Change Runtime type` $\\to$ `Hardware accelerator: GPU`\n",
    "2.   **Are running this tutorial from _your_ Google Drive. You can do this by going to: `File` $\\to$ `Save a Copy in Drive`.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title Fetch configuration file\n",
    "# fetch the configuration (config) file to be used for this tutorial\n",
    "!wget https://raw.githubusercontent.com/ivadomed/ivadomed/master/ivadomed/config/config.json ./content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uzOt6ugooys4",
    "outputId": "b78724a5-06f4-4b6a-f694-c2151506c5f8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in links: https://download.pytorch.org/whl/torch_stable.html\n",
      "Collecting torch==1.8.0+cu111\n",
      "  Downloading https://download.pytorch.org/whl/cu111/torch-1.8.0%2Bcu111-cp37-cp37m-linux_x86_64.whl (1982.2 MB)\n",
      "\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                  | 834.1 MB 1.6 MB/s eta 0:12:08tcmalloc: large alloc 1147494400 bytes == 0x5624825fa000 @  0x7fc3b5af8615 0x56244888e4cc 0x56244896e47a 0x5624488912ed 0x562448982e1d 0x562448904e99 0x5624488ff9ee 0x562448892bda 0x562448904d00 0x5624488ff9ee 0x562448892bda 0x562448901737 0x562448983c66 0x562448900daf 0x562448983c66 0x562448900daf 0x562448983c66 0x562448900daf 0x562448893039 0x5624488d6409 0x562448891c52 0x562448904c25 0x5624488ff9ee 0x562448892bda 0x562448901737 0x5624488ff9ee 0x562448892bda 0x562448900915 0x562448892afa 0x562448900c0d 0x5624488ff9ee\n",
      "\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà               | 1055.7 MB 1.7 MB/s eta 0:09:00tcmalloc: large alloc 1434370048 bytes == 0x5624c6c50000 @  0x7fc3b5af8615 0x56244888e4cc 0x56244896e47a 0x5624488912ed 0x562448982e1d 0x562448904e99 0x5624488ff9ee 0x562448892bda 0x562448904d00 0x5624488ff9ee 0x562448892bda 0x562448901737 0x562448983c66 0x562448900daf 0x562448983c66 0x562448900daf 0x562448983c66 0x562448900daf 0x562448893039 0x5624488d6409 0x562448891c52 0x562448904c25 0x5624488ff9ee 0x562448892bda 0x562448901737 0x5624488ff9ee 0x562448892bda 0x562448900915 0x562448892afa 0x562448900c0d 0x5624488ff9ee\n",
      "\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã          | 1336.2 MB 1.7 MB/s eta 0:06:27tcmalloc: large alloc 1792966656 bytes == 0x56244ba82000 @  0x7fc3b5af8615 0x56244888e4cc 0x56244896e47a 0x5624488912ed 0x562448982e1d 0x562448904e99 0x5624488ff9ee 0x562448892bda 0x562448904d00 0x5624488ff9ee 0x562448892bda 0x562448901737 0x562448983c66 0x562448900daf 0x562448983c66 0x562448900daf 0x562448983c66 0x562448900daf 0x562448893039 0x5624488d6409 0x562448891c52 0x562448904c25 0x5624488ff9ee 0x562448892bda 0x562448901737 0x5624488ff9ee 0x562448892bda 0x562448900915 0x562448892afa 0x562448900c0d 0x5624488ff9ee\n",
      "\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 1691.1 MB 1.3 MB/s eta 0:03:37tcmalloc: large alloc 2241208320 bytes == 0x5624b686a000 @  0x7fc3b5af8615 0x56244888e4cc 0x56244896e47a 0x5624488912ed 0x562448982e1d 0x562448904e99 0x5624488ff9ee 0x562448892bda 0x562448904d00 0x5624488ff9ee 0x562448892bda 0x562448901737 0x562448983c66 0x562448900daf 0x562448983c66 0x562448900daf 0x562448983c66 0x562448900daf 0x562448893039 0x5624488d6409 0x562448891c52 0x562448904c25 0x5624488ff9ee 0x562448892bda 0x562448901737 0x5624488ff9ee 0x562448892bda 0x562448900915 0x562448892afa 0x562448900c0d 0x5624488ff9ee\n",
      "\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1982.2 MB 1.5 MB/s eta 0:00:01tcmalloc: large alloc 1982251008 bytes == 0x56253c1cc000 @  0x7fc3b5af71e7 0x5624488c4067 0x56244888e4cc 0x56244896e47a 0x5624488912ed 0x562448982e1d 0x562448904e99 0x5624488ff9ee 0x562448892bda 0x562448900c0d 0x5624488ff9ee 0x562448892bda 0x562448900c0d 0x5624488ff9ee 0x562448892bda 0x562448900c0d 0x5624488ff9ee 0x562448892bda 0x562448900c0d 0x5624488ff9ee 0x562448892bda 0x562448900c0d 0x562448892afa 0x562448900c0d 0x5624488ff9ee 0x562448892bda 0x562448901737 0x5624488ff9ee 0x562448892bda 0x562448901737 0x5624488ff9ee\n",
      "tcmalloc: large alloc 2477817856 bytes == 0x5625b2438000 @  0x7fc3b5af8615 0x56244888e4cc 0x56244896e47a 0x5624488912ed 0x562448982e1d 0x562448904e99 0x5624488ff9ee 0x562448892bda 0x562448900c0d 0x5624488ff9ee 0x562448892bda 0x562448900c0d 0x5624488ff9ee 0x562448892bda 0x562448900c0d 0x5624488ff9ee 0x562448892bda 0x562448900c0d 0x5624488ff9ee 0x562448892bda 0x562448900c0d 0x562448892afa 0x562448900c0d 0x5624488ff9ee 0x562448892bda 0x562448901737 0x5624488ff9ee 0x562448892bda 0x562448901737 0x5624488ff9ee 0x562448893271\n",
      "\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1982.2 MB 1.1 kB/s \n",
      "\u001b[?25hCollecting torchvision==0.9.0+cu111\n",
      "  Downloading https://download.pytorch.org/whl/cu111/torchvision-0.9.0%2Bcu111-cp37-cp37m-linux_x86_64.whl (17.6 MB)\n",
      "\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 17.6 MB 902 kB/s \n",
      "\u001b[?25hCollecting torchtext==0.9.0\n",
      "  Downloading torchtext-0.9.0-cp37-cp37m-manylinux1_x86_64.whl (7.1 MB)\n",
      "\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7.1 MB 5.6 MB/s \n",
      "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torch==1.8.0+cu111) (1.19.5)\n",
      "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch==1.8.0+cu111) (3.10.0.2)\n",
      "Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.7/dist-packages (from torchvision==0.9.0+cu111) (7.1.2)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from torchtext==0.9.0) (2.23.0)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from torchtext==0.9.0) (4.62.3)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext==0.9.0) (3.0.4)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext==0.9.0) (1.24.3)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext==0.9.0) (2.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext==0.9.0) (2021.10.8)\n",
      "Installing collected packages: torch, torchvision, torchtext\n",
      "  Attempting uninstall: torch\n",
      "    Found existing installation: torch 1.10.0+cu111\n",
      "    Uninstalling torch-1.10.0+cu111:\n",
      "      Successfully uninstalled torch-1.10.0+cu111\n",
      "  Attempting uninstall: torchvision\n",
      "    Found existing installation: torchvision 0.11.1+cu111\n",
      "    Uninstalling torchvision-0.11.1+cu111:\n",
      "      Successfully uninstalled torchvision-0.11.1+cu111\n",
      "  Attempting uninstall: torchtext\n",
      "    Found existing installation: torchtext 0.11.0\n",
      "    Uninstalling torchtext-0.11.0:\n",
      "      Successfully uninstalled torchtext-0.11.0\n",
      "Successfully installed torch-1.8.0+cu111 torchtext-0.9.0 torchvision-0.9.0+cu111\n",
      "\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 562 kB 5.4 MB/s \n",
      "\u001b[?25h  Building wheel for imgaug (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 215 kB 5.3 MB/s \n",
      "\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3.2 MB 38.5 MB/s \n",
      "\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 11.2 MB 37.3 MB/s \n",
      "\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4.1 MB 54 kB/s \n",
      "\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3.3 MB 37.5 MB/s \n",
      "\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 57 kB 4.6 MB/s \n",
      "\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 873 kB 32.9 MB/s \n",
      "\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 55 kB 3.9 MB/s \n",
      "\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 101 kB 8.5 MB/s \n",
      "\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1.3 MB 27.2 MB/s \n",
      "\u001b[?25h"
     ]
    }
   ],
   "source": [
    "# @title Install Dependencies\n",
    "!pip install imgaug==0.2.5 --quiet \n",
    "!pip install ivadomed --quiet \n",
    "\n",
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "G8cIbs-IrwtW",
    "outputId": "17dee5c9-864f-4189-c7e6-62854c9b5d25"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2021-11-18 17:08:58.880\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mivadomed.utils\u001b[0m:\u001b[36minit_ivadomed\u001b[0m:\u001b[36m408\u001b[0m - \u001b[1m\n",
      "ivadomed (2.9.0)\n",
      "\u001b[0m\n",
      "Trying URL: https://github.com/ivadomed/data_example_spinegeneric/archive/r20200825.zip\n",
      "Downloading: data_example_spinegeneric-r20200825.zip\n",
      "Unzip data to: /tmp/tmpl29u9rom\n",
      "Removing temporary folders...\n",
      "Folder Created: /content/data_example_spinegeneric\n",
      "--2021-11-18 17:09:41--  https://raw.githubusercontent.com/ivadomed/ivadomed/master/ivadomed/config/config.json\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 3699 (3.6K) [text/plain]\n",
      "Saving to: ‚Äòconfig.json‚Äô\n",
      "\n",
      "config.json         100%[===================>]   3.61K  --.-KB/s    in 0s      \n",
      "\n",
      "2021-11-18 17:09:41 (43.6 MB/s) - ‚Äòconfig.json‚Äô saved [3699/3699]\n",
      "\n",
      "--2021-11-18 17:09:41--  http://./content\n",
      "Resolving . (.)... failed: No address associated with hostname.\n",
      "wget: unable to resolve host address ‚Äò.‚Äô\n",
      "FINISHED --2021-11-18 17:09:41--\n",
      "Total wall clock time: 0.2s\n",
      "Downloaded: 1 files, 3.6K in 0s (43.6 MB/s)\n"
     ]
    }
   ],
   "source": [
    "# @title Run Me for Downloading the Dataset!\n",
    "\n",
    "# @markdown We will be using a publicly-available dataset consisting of the MRI data of the spinal cord. \n",
    "# @markdown More details on this dataset can be found in \n",
    "# @markdown Tutorial 1: [One-class segmentation with 2D U-Net](https://ivadomed.org/tutorials/one_class_segmentation_2d_unet.html).\n",
    "\n",
    "# download the dataset\n",
    "!ivadomed_download_data -d data_example_spinegeneric"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yrMSqatm67i5"
   },
   "source": [
    "#### Configuration File\n",
    "\n",
    "In this tutorial, we will be using the configuration file: `ivadomed/config/config.json`. This is already downloaded for you and can be seen under Colab's `Files` (üìÅ) tab on the left.\n",
    "\n",
    "Open this file; this is the same configuration file used in the [first tutorial](https://ivadomed.org/tutorials/one_class_segmentation_2d_unet.html) and will be modified as mentioned in the [Technical features](https://ivadomed.org/technical_features.html#uncertainty-measures). Please ensure that the `path_data` key points to the correct location of the dataset. The parameters that are of interest for this tutorial are as follows: \n",
    "\n",
    "1. `path_data` -  Location of the directory containing the dataset. \n",
    "```json\n",
    "    \"path_data\": \"data_example_spinegeneric\"\n",
    "```\n",
    "\n",
    "2. `path_output` -  Location of the directory containing the trained model. To avoid having to train a model from scratch, there is a pre-trained model for spinal cord segmentation in the folder named trained_model, in the downloaded dataset. Modify the path so it points to the location of the trained model.\n",
    "```json\n",
    "    \"path_output\": \"<PATH_TO_DATASET>/data_example_spinegeneric/trained_model\"\n",
    "```\n",
    "\n",
    "3. `command` - The task to perform. Since we are interested in inference on a trained model, we set the command to \"test\" as shown below. \n",
    "```json\n",
    "    \"command\": \"test\"\n",
    "```\n",
    "\n",
    "4. `uncertainty` - The type of uncertainty to estimate. Available choices are \"epistemic\" and \"aleatoric\". Note that both can be true. More details on the implementation can be found in [Technical features](https://ivadomed.org/technical_features.html#uncertainty-measures). `\"n_it\"` controls the number of Monte Carlo iterations that are performed to estimate the uncertainty. It is set to a positive integer for this tutorial (e.g. `15`).\n",
    "```json\n",
    "    \"uncertainty\": {\n",
    "        \"epistemic\": true,\n",
    "        \"aleatoric\": true,\n",
    "        \"n_it\": 15\n",
    "    }\n",
    "```\n",
    "\n",
    "5. `transformation` - The transformations performed as a part of data augmentation. If aleatoric uncertainty is enabled, the data augmentation that will be performed is the same as the one performed for the training. Note that only transformations for which an `undo_transform` (i.e. inverse transformation) is available will be performed since these inverse transformations are required to reconstruct the predicted volume.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JIqUMWMSA3Fl"
   },
   "source": [
    "### Modify the Config File\n",
    "\n",
    "Open the `config.json` file under the \"Files\" tab on the left. This should let you edit the contents of the json file as mentioned above. Change the following parameters:\n",
    "\n",
    "1. \n",
    "```json\n",
    "    \"command\": \"test\"\n",
    "```\n",
    "2. \n",
    "```json\n",
    "    \"path_output\": \"data_example_spinegeneric/trained_model\"\n",
    "```\n",
    "3. \n",
    "```json\n",
    "    \"debugging\": true\n",
    "```\n",
    "4. \n",
    "```json\n",
    "    \"uncertainty\": {\n",
    "        \"epistemic\": true,\n",
    "        \"aleatoric\": true,\n",
    "        \"n_it\": 15\n",
    "    }\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QrtC-Etn66Mm",
    "outputId": "8c5982bc-1568-40eb-eee6-9b15ed430e34"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2021-11-18 17:11:09.612\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mivadomed.utils\u001b[0m:\u001b[36minit_ivadomed\u001b[0m:\u001b[36m408\u001b[0m - \u001b[1m\n",
      "ivadomed (2.9.0)\n",
      "\u001b[0m\n",
      "\u001b[32m2021-11-18 17:11:09.615\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mivadomed.utils\u001b[0m:\u001b[36mget_path_output\u001b[0m:\u001b[36m371\u001b[0m - \u001b[1mCLI flag --path-output not used to specify output directory. Will check config file for directory...\u001b[0m\n",
      "\u001b[32m2021-11-18 17:11:09.615\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mivadomed.utils\u001b[0m:\u001b[36mget_path_data\u001b[0m:\u001b[36m383\u001b[0m - \u001b[1mCLI flag --path-data not used to specify BIDS data directory. Will check config file for directory...\u001b[0m\n",
      "\u001b[32m2021-11-18 17:11:09.615\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mivadomed.main\u001b[0m:\u001b[36mset_output_path\u001b[0m:\u001b[36m198\u001b[0m - \u001b[1mOutput path already exists: data_example_spinegeneric/trained_model\u001b[0m\n",
      "\u001b[32m2021-11-18 17:11:09.720\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mivadomed.utils\u001b[0m:\u001b[36mdefine_device\u001b[0m:\u001b[36m135\u001b[0m - \u001b[1mUsing GPU ID 0\u001b[0m\n",
      "\u001b[32m2021-11-18 17:11:09.721\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mivadomed.utils\u001b[0m:\u001b[36mdisplay_selected_model_spec\u001b[0m:\u001b[36m145\u001b[0m - \u001b[1mSelected architecture: Unet, with the following parameters:\u001b[0m\n",
      "\u001b[32m2021-11-18 17:11:09.721\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mivadomed.utils\u001b[0m:\u001b[36mdisplay_selected_model_spec\u001b[0m:\u001b[36m148\u001b[0m - \u001b[1m\tdropout_rate: 0.3\u001b[0m\n",
      "\u001b[32m2021-11-18 17:11:09.722\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mivadomed.utils\u001b[0m:\u001b[36mdisplay_selected_model_spec\u001b[0m:\u001b[36m148\u001b[0m - \u001b[1m\tbn_momentum: 0.1\u001b[0m\n",
      "\u001b[32m2021-11-18 17:11:09.722\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mivadomed.utils\u001b[0m:\u001b[36mdisplay_selected_model_spec\u001b[0m:\u001b[36m148\u001b[0m - \u001b[1m\tdepth: 3\u001b[0m\n",
      "\u001b[32m2021-11-18 17:11:09.722\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mivadomed.utils\u001b[0m:\u001b[36mdisplay_selected_model_spec\u001b[0m:\u001b[36m148\u001b[0m - \u001b[1m\tis_2d: True\u001b[0m\n",
      "\u001b[32m2021-11-18 17:11:09.723\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mivadomed.utils\u001b[0m:\u001b[36mdisplay_selected_model_spec\u001b[0m:\u001b[36m148\u001b[0m - \u001b[1m\tfinal_activation: sigmoid\u001b[0m\n",
      "\u001b[32m2021-11-18 17:11:09.723\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mivadomed.utils\u001b[0m:\u001b[36mdisplay_selected_model_spec\u001b[0m:\u001b[36m148\u001b[0m - \u001b[1m\tfolder_name: my_model\u001b[0m\n",
      "\u001b[32m2021-11-18 17:11:09.723\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mivadomed.utils\u001b[0m:\u001b[36mdisplay_selected_model_spec\u001b[0m:\u001b[36m148\u001b[0m - \u001b[1m\tin_channel: 1\u001b[0m\n",
      "\u001b[32m2021-11-18 17:11:09.724\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mivadomed.utils\u001b[0m:\u001b[36mdisplay_selected_model_spec\u001b[0m:\u001b[36m148\u001b[0m - \u001b[1m\tout_channel: 1\u001b[0m\n",
      "/usr/local/lib/python3.7/dist-packages/bids/config.py:40: FutureWarning: Setting 'extension_initial_dot' will be removed in pybids 0.16.\n",
      "  FutureWarning)\n",
      "\u001b[32m2021-11-18 17:11:09.732\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mivadomed.loader.bids_dataframe\u001b[0m:\u001b[36mwrite_derivatives_dataset_description\u001b[0m:\u001b[36m304\u001b[0m - \u001b[33m\u001b[1m/content/data_example_spinegeneric/derivatives/dataset_description.json not found. Please ensure a full path is specified in the configuration file. Will attempt to create a place holder description file for now at/content/data_example_spinegeneric/derivatives/dataset_description.json.\u001b[0m\n",
      "/usr/local/lib/python3.7/dist-packages/bids/layout/validation.py:149: UserWarning: The PipelineDescription field was superseded by GeneratedBy in BIDS 1.4.0. You can use ``pybids upgrade`` to update your derivative dataset.\n",
      "  warnings.warn(\"The PipelineDescription field was superseded \"\n",
      "\u001b[32m2021-11-18 17:11:11.080\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mivadomed.loader.bids_dataframe\u001b[0m:\u001b[36msave\u001b[0m:\u001b[36m289\u001b[0m - \u001b[1mDataframe has been saved in data_example_spinegeneric/trained_model/bids_dataframe.csv.\u001b[0m\n",
      "\u001b[32m2021-11-18 17:11:11.084\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mivadomed.loader.utils\u001b[0m:\u001b[36msplit_dataset\u001b[0m:\u001b[36m102\u001b[0m - \u001b[33m\u001b[1mAfter splitting: train, validation and test fractions are respectively 0.6, 0.2 and 0.2 of participant_id.\u001b[0m\n",
      "\u001b[32m2021-11-18 17:11:11.981\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mivadomed.transforms\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m132\u001b[0m - \u001b[1mElasticTransform transform not included since no undo_transform available for it.\u001b[0m\n",
      "\u001b[32m2021-11-18 17:11:11.981\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mivadomed.utils\u001b[0m:\u001b[36mdisplay_selected_transfoms\u001b[0m:\u001b[36m158\u001b[0m - \u001b[1mSelected transformations for the ['testing'] dataset:\u001b[0m\n",
      "\u001b[32m2021-11-18 17:11:11.981\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mivadomed.utils\u001b[0m:\u001b[36mdisplay_selected_transfoms\u001b[0m:\u001b[36m160\u001b[0m - \u001b[1m\tResample: {'hspace': 0.75, 'wspace': 0.75, 'dspace': 1}\u001b[0m\n",
      "\u001b[32m2021-11-18 17:11:11.982\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mivadomed.utils\u001b[0m:\u001b[36mdisplay_selected_transfoms\u001b[0m:\u001b[36m160\u001b[0m - \u001b[1m\tCenterCrop: {'size': [128, 128]}\u001b[0m\n",
      "\u001b[32m2021-11-18 17:11:11.982\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mivadomed.utils\u001b[0m:\u001b[36mdisplay_selected_transfoms\u001b[0m:\u001b[36m160\u001b[0m - \u001b[1m\tRandomAffine: {'degrees': 5, 'scale': [0.1, 0.1, 0.0], 'translate': [0.03, 0.03, 0.0], 'applied_to': ['im', 'gt']}\u001b[0m\n",
      "\u001b[32m2021-11-18 17:11:11.982\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mivadomed.utils\u001b[0m:\u001b[36mdisplay_selected_transfoms\u001b[0m:\u001b[36m160\u001b[0m - \u001b[1m\tElasticTransform: {'alpha_range': [28.0, 30.0], 'sigma_range': [3.5, 4.5], 'p': 0.1, 'applied_to': ['im', 'gt']}\u001b[0m\n",
      "\u001b[32m2021-11-18 17:11:11.982\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mivadomed.utils\u001b[0m:\u001b[36mdisplay_selected_transfoms\u001b[0m:\u001b[36m160\u001b[0m - \u001b[1m\tNormalizeInstance: {'applied_to': ['im']}\u001b[0m\n",
      "\u001b[32m2021-11-18 17:11:11.983\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mivadomed.transforms\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m132\u001b[0m - \u001b[1mElasticTransform transform not included since no undo_transform available for it.\u001b[0m\n",
      "Loading dataset: 100% 6/6 [00:00<00:00, 102.15it/s]\n",
      "\u001b[32m2021-11-18 17:11:18.897\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mivadomed.loader.loader\u001b[0m:\u001b[36mload_dataset\u001b[0m:\u001b[36m114\u001b[0m - \u001b[1mLoaded 94 axial slices for the testing set.\u001b[0m\n",
      "\u001b[32m2021-11-18 17:11:18.897\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mivadomed.testing\u001b[0m:\u001b[36mtest\u001b[0m:\u001b[36m51\u001b[0m - \u001b[1mLoading model: data_example_spinegeneric/trained_model/best_model.pt\u001b[0m\n",
      "/usr/local/lib/python3.7/dist-packages/torch/serialization.py:656: SourceChangeWarning: source code of class 'ivadomed.models.Unet' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
      "  warnings.warn(msg, SourceChangeWarning)\n",
      "/usr/local/lib/python3.7/dist-packages/torch/serialization.py:656: SourceChangeWarning: source code of class 'ivadomed.models.Encoder' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
      "  warnings.warn(msg, SourceChangeWarning)\n",
      "/usr/local/lib/python3.7/dist-packages/torch/serialization.py:656: SourceChangeWarning: source code of class 'torch.nn.modules.container.ModuleList' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
      "  warnings.warn(msg, SourceChangeWarning)\n",
      "/usr/local/lib/python3.7/dist-packages/torch/serialization.py:656: SourceChangeWarning: source code of class 'ivadomed.models.DownConv' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
      "  warnings.warn(msg, SourceChangeWarning)\n",
      "/usr/local/lib/python3.7/dist-packages/torch/serialization.py:656: SourceChangeWarning: source code of class 'torch.nn.modules.conv.Conv2d' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
      "  warnings.warn(msg, SourceChangeWarning)\n",
      "/usr/local/lib/python3.7/dist-packages/torch/serialization.py:656: SourceChangeWarning: source code of class 'torch.nn.modules.batchnorm.BatchNorm2d' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
      "  warnings.warn(msg, SourceChangeWarning)\n",
      "/usr/local/lib/python3.7/dist-packages/torch/serialization.py:656: SourceChangeWarning: source code of class 'torch.nn.modules.dropout.Dropout2d' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
      "  warnings.warn(msg, SourceChangeWarning)\n",
      "/usr/local/lib/python3.7/dist-packages/torch/serialization.py:656: SourceChangeWarning: source code of class 'torch.nn.modules.pooling.MaxPool2d' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
      "  warnings.warn(msg, SourceChangeWarning)\n",
      "/usr/local/lib/python3.7/dist-packages/torch/serialization.py:656: SourceChangeWarning: source code of class 'ivadomed.models.Decoder' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
      "  warnings.warn(msg, SourceChangeWarning)\n",
      "/usr/local/lib/python3.7/dist-packages/torch/serialization.py:656: SourceChangeWarning: source code of class 'ivadomed.models.UpConv' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
      "  warnings.warn(msg, SourceChangeWarning)\n",
      "\u001b[32m2021-11-18 17:11:21.541\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mivadomed.testing\u001b[0m:\u001b[36mtest\u001b[0m:\u001b[36m70\u001b[0m - \u001b[1mComputing model uncertainty over 10 iterations.\u001b[0m\n",
      "Inference - Iteration 0: 100% 6/6 [00:10<00:00,  1.79s/it]\n",
      "Inference - Iteration 1: 100% 6/6 [00:05<00:00,  1.19it/s]\n",
      "Inference - Iteration 2: 100% 6/6 [00:04<00:00,  1.26it/s]\n",
      "Inference - Iteration 3: 100% 6/6 [00:04<00:00,  1.27it/s]\n",
      "Inference - Iteration 4: 100% 6/6 [00:04<00:00,  1.22it/s]\n",
      "Inference - Iteration 5: 100% 6/6 [00:04<00:00,  1.27it/s]\n",
      "Inference - Iteration 6: 100% 6/6 [00:04<00:00,  1.26it/s]\n",
      "Inference - Iteration 7: 100% 6/6 [00:04<00:00,  1.21it/s]\n",
      "Inference - Iteration 8: 100% 6/6 [00:04<00:00,  1.23it/s]\n",
      "Inference - Iteration 9: 100% 6/6 [00:04<00:00,  1.26it/s]\n",
      "Uncertainty Computation: 100% 6/6 [00:41<00:00,  6.99s/it]\n",
      "Inference - Iteration 10: 100% 6/6 [00:09<00:00,  1.59s/it]\n",
      "\u001b[32m2021-11-18 17:15:21.196\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mivadomed.testing\u001b[0m:\u001b[36mtest\u001b[0m:\u001b[36m87\u001b[0m - \u001b[1m{'dice_score': 0.8902438680723904, 'multi_class_dice_score': 0.8902438680723904, 'precision_score': 0.8902424710595589, 'recall_score': 0.8927448282084386, 'specificity_score': 0.9998551088037474, 'intersection_over_union': 0.8025785222811419, 'accuracy_score': 0.999715174700608, 'hausdorff_score': 0.06832593207064888}\u001b[0m\n",
      "\u001b[32m2021-11-18 17:15:21.213\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mivadomed.evaluation\u001b[0m:\u001b[36mevaluate\u001b[0m:\u001b[36m33\u001b[0m - \u001b[1m\n",
      "Run Evaluation on data_example_spinegeneric/trained_model/pred_masks\n",
      "\u001b[0m\n",
      "Evaluation: 100% 6/6 [00:08<00:00,  1.41s/it]\n",
      "\u001b[32m2021-11-18 17:15:29.652\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mivadomed.evaluation\u001b[0m:\u001b[36mevaluate\u001b[0m:\u001b[36m113\u001b[0m - \u001b[1m                     avd_class0  ...  vol_pred_class0\n",
      "image_id                         ...                 \n",
      "sub-unf01_T1w          0.070805  ...      5724.999454\n",
      "sub-unf01_T2w          0.053561  ...      5831.249444\n",
      "sub-mpicbs06_T2star    0.075322  ...      4907.499532\n",
      "sub-mpicbs06_T2w       0.005667  ...      4879.999535\n",
      "sub-unf01_T2star       0.023846  ...      5903.749437\n",
      "\n",
      "[5 rows x 16 columns]\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# @title Run Uncertainty Estimation\n",
    "\n",
    "# @markdown Once the configuration file has been modified, run the inference with the following command:\n",
    "# @markdown ```shell\n",
    "# @markdown   ivadomed --test -c config.json\n",
    "# @markdown ```\n",
    "\n",
    "# run uncertainty estimation\n",
    "!ivadomed --test -c config.json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CEph9yzPQ5ZC"
   },
   "source": [
    "If aleatoric uncertainty was enabled, then data augmentation operations will be performed at the test time, as indicated in the terminal output (see below). Note that `ElasticTransform` has been deactivated because `undo_transform` function is not available for it.\n",
    "\n",
    "```\n",
    "  Selected transformations for the ['testing'] dataset:\n",
    "   Resample: {'hspace': 0.75, 'wspace': 0.75, 'dspace': 1}\n",
    "   CenterCrop: {'size': [128, 128]}\n",
    "   RandomAffine: {'degrees': 5, 'scale': [0.1, 0.1], 'translate': [0.03, 0.03], 'applied_to': ['im', 'gt']}\n",
    "   ElasticTransform: {'alpha_range': [28.0, 30.0], 'sigma_range': [3.5, 4.5], 'p': 0.1, 'applied_to': ['im', 'gt']}\n",
    "   NumpyToTensor: {}\n",
    "   NormalizeInstance: {'applied_to': ['im']}\n",
    "  ElasticTransform transform not included since no undo_transform available for it.\n",
    "```\n",
    "\n",
    ".... otherwise, only preprocessing and data normalization are performed, see below:\n",
    "\n",
    "```\n",
    "  Selected transformations for the ['testing'] dataset:\n",
    "   Resample: {'hspace': 0.75, 'wspace': 0.75, 'dspace': 1}\n",
    "   CenterCrop: {'size': [128, 128]}\n",
    "   NumpyToTensor: {}\n",
    "   NormalizeInstance: {'applied_to': ['im']}\n",
    "```\n",
    "\n",
    "For each testing image, `\"n_it\"` Monte Carlo samples for that image are segmented using the trained model and saved under `pred_masks`, with the iteration number as suffix (e.g. `sub-001_pred_00.nii.gz ‚Ä¶ sub-001_pred_19.nii.gz`).\n",
    "\n",
    "```\n",
    "  Computing model uncertainty over 20 iterations.\n",
    "    Inference - Iteration 0: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 5/5 [00:11<00:00,  2.27s/it]     \n",
    "    Inference - Iteration 1: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 5/5 [00:09<00:00,  1.81s/it]\n",
    "    Inference - Iteration 2: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 5/5 [00:09<00:00,  1.96s/it]\n",
    "    Inference - Iteration 3: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 5/5 [00:08<00:00,  1.66s/it]\n",
    "    Inference - Iteration 4: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 5/5 [00:08<00:00,  1.69s/it]\n",
    "    Inference - Iteration 5: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 5/5 [00:09<00:00,  1.92s/it]\n",
    "    Inference - Iteration 6: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 5/5 [00:08<00:00,  1.74s/it]\n",
    "    Inference - Iteration 7: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 5/5 [00:08<00:00,  1.74s/it]\n",
    "    Inference - Iteration 8: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 5/5 [00:09<00:00,  1.83s/it]\n",
    "    Inference - Iteration 9: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 5/5 [00:07<00:00,  1.59s/it]\n",
    "    Inference - Iteration 10: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 5/5 [00:09<00:00,  1.85s/it]\n",
    "    Inference - Iteration 11: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 5/5 [00:09<00:00,  1.85s/it]\n",
    "    Inference - Iteration 12: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 5/5 [00:09<00:00,  1.92s/it]\n",
    "    Inference - Iteration 13: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 5/5 [00:09<00:00,  1.83s/it]\n",
    "    Inference - Iteration 14: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 5/5 [00:09<00:00,  1.84s/it]\n",
    "```\n",
    "\n",
    "The Monte Carlo samples are then used to compute uncertainty measures for each image. The results are saved under `pred_masks`.\n",
    "```\n",
    "  Uncertainty Computation: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 5/5 [01:31<00:00, 18.28s/it]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-Us9-l2YVn-V",
    "outputId": "480f285f-81f2-4081-e896-acb5dc66a111"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Zip file created!\n"
     ]
    }
   ],
   "source": [
    "# @title Save and Download the results!\n",
    "# @markdown Now that we have the uncertainty estimates, we would like to download\n",
    "# @markdown the results locally for further anaylsis. For that, we first\n",
    "# @markdown create a `.zip`file of the results folder and then download\n",
    "# @markdown the zipped file manually. \n",
    "\n",
    "# first, zip the results folder\n",
    "!zip -r --quiet spineGeneric_unc.zip ./data_example_spinegeneric/trained_model/\n",
    "print(\"Zip file created!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "F2okWrkETGYL"
   },
   "source": [
    "Note that six files are generated during this process for each testing image:\n",
    "\n",
    "* `*_soft.nii.gz`: Soft segmentation (i.e. values between 0 and 1) which is generated by averaging the Monte Carlo samples.\n",
    "\n",
    "* `*_pred.nii.gz`: Binary segmentation obtained by thresholding `*_soft.nii.gz` with `1 / (Number of Monte Carlo iterations)` i.e. `1/n_it`.\n",
    "\n",
    "* `*_unc-vox.nii.gz`: Voxel-wise measure of uncertainty derived from the entropy of the Monte Carlo samples. The higher a given voxel value is, the more uncertain is the prediction for this voxel.\n",
    "\n",
    "* `*_unc-avgUnc.nii.gz`: Structure-wise measure of uncertainty derived from the mean value of `*_unc-vox.nii.gz` within a given connected object (e.g. a lesion, grey matter).\n",
    "\n",
    "* `*_unc-cv.nii.gz`: Structure-wise measure of uncertainty derived from the coefficient of variation of the volume of a given connected object across the Monte Carlo samples. The higher the value for a given voxel, the more uncertain is the prediction for this voxel.\n",
    "\n",
    "* `*_unc-iou.nii.gz`: Structure-wise measure of uncertainty derived from the Intersection-over-Union (IoU) of the predictions of a given connected object across the Monte Carlo samples. The lower the value for a given voxel, the more uncertain is the prediction for this voxel.\n",
    "\n",
    "These files can further be used for post-processing to refine the segmentation. For example, the voxels depicted in pink under the \"Uncertainty\" panel are more uncertain than the ones in blue: therefore, we can further refine the model's prediction by removing the voxels with low uncertainty (in blue) **AND** low prediction values (in dark red under the \"Model Prediction\" panel) from the foreground class.  \n",
    "\n",
    "<img src=\"https://raw.githubusercontent.com/ivadomed/doc-figures/main/tutorials/uncertainty/uncertainty_tutorial.png\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ihqD2cacWdT1"
   },
   "source": [
    "And that concludes the tutorial on how to use the in-built uncertainty estimation measures in `ivadomed` for spinal cord segmentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1dNLUwA5rw3k"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "ivadomed_tutorial-3_uncertainty-estimation.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
