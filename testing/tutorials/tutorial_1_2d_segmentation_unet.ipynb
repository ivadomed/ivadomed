{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f9egIMJiOj75"
      },
      "source": [
        "## Welcome to the ivadomed's first tutorial: **One-class segmentation with 2D U-Net**\n",
        "\n",
        "In this tutorial, we will be looking at how to train a two-dimensional (2D) segmentation model for segmenting the spinal cord with a single label on multiple Magnetic Resonance (MR) contrasts. The model will then be evaluted using various metrics like the Dice coefficient, Hausdorff distance, etc. This tutorial also provides visualizations of training curves and the segmented images on Tensorboard. \n",
        "\n",
        "‚ö†Ô∏è Before getting started, please ensure that you: \n",
        "\n",
        "1.   Are connected to the GPU. You can do this by doing the following from the task bar on the top: `Runtime` $\\to$ `Change Runtime type` $\\to$ `Hardware accelerator: GPU`\n",
        "2.   **Are running this tutorial from _your_ Google Drive. You can do this by going to: `File` $\\to$ `Save a Copy in Drive`.**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# @title Fetch configuration file\n",
        "# fetch the configuration (config) file to be used for this tutorial\n",
        "!wget https://raw.githubusercontent.com/ivadomed/ivadomed/master/ivadomed/config/config.json ./content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NTmS_K7wHUSN",
        "outputId": "34f8d16f-0816-404b-88f5-b6729c6f4cb3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[?25l\r\u001b[K     |‚ñã                               | 10 kB 16.5 MB/s eta 0:00:01\r\u001b[K     |‚ñà‚ñè                              | 20 kB 19.7 MB/s eta 0:00:01\r\u001b[K     |‚ñà‚ñä                              | 30 kB 20.1 MB/s eta 0:00:01\r\u001b[K     |‚ñà‚ñà‚ñé                             | 40 kB 17.0 MB/s eta 0:00:01\r\u001b[K     |‚ñà‚ñà‚ñà                             | 51 kB 12.3 MB/s eta 0:00:01\r\u001b[K     |‚ñà‚ñà‚ñà‚ñå                            | 61 kB 13.8 MB/s eta 0:00:01\r\u001b[K     |‚ñà‚ñà‚ñà‚ñà                            | 71 kB 12.2 MB/s eta 0:00:01\r\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñã                           | 81 kB 13.2 MB/s eta 0:00:01\r\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                          | 92 kB 11.3 MB/s eta 0:00:01\r\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                          | 102 kB 11.6 MB/s eta 0:00:01\r\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                         | 112 kB 11.6 MB/s eta 0:00:01\r\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                         | 122 kB 11.6 MB/s eta 0:00:01\r\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                        | 133 kB 11.6 MB/s eta 0:00:01\r\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                       | 143 kB 11.6 MB/s eta 0:00:01\r\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                       | 153 kB 11.6 MB/s eta 0:00:01\r\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                      | 163 kB 11.6 MB/s eta 0:00:01\r\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                      | 174 kB 11.6 MB/s eta 0:00:01\r\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                     | 184 kB 11.6 MB/s eta 0:00:01\r\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                     | 194 kB 11.6 MB/s eta 0:00:01\r\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                    | 204 kB 11.6 MB/s eta 0:00:01\r\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé                   | 215 kB 11.6 MB/s eta 0:00:01\r\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ                   | 225 kB 11.6 MB/s eta 0:00:01\r\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç                  | 235 kB 11.6 MB/s eta 0:00:01\r\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà                  | 245 kB 11.6 MB/s eta 0:00:01\r\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                 | 256 kB 11.6 MB/s eta 0:00:01\r\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                | 266 kB 11.6 MB/s eta 0:00:01\r\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                | 276 kB 11.6 MB/s eta 0:00:01\r\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé               | 286 kB 11.6 MB/s eta 0:00:01\r\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ               | 296 kB 11.6 MB/s eta 0:00:01\r\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå              | 307 kB 11.6 MB/s eta 0:00:01\r\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà              | 317 kB 11.6 MB/s eta 0:00:01\r\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã             | 327 kB 11.6 MB/s eta 0:00:01\r\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè            | 337 kB 11.6 MB/s eta 0:00:01\r\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ            | 348 kB 11.6 MB/s eta 0:00:01\r\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç           | 358 kB 11.6 MB/s eta 0:00:01\r\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà           | 368 kB 11.6 MB/s eta 0:00:01\r\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå          | 378 kB 11.6 MB/s eta 0:00:01\r\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè         | 389 kB 11.6 MB/s eta 0:00:01\r\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä         | 399 kB 11.6 MB/s eta 0:00:01\r\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé        | 409 kB 11.6 MB/s eta 0:00:01\r\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ        | 419 kB 11.6 MB/s eta 0:00:01\r\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå       | 430 kB 11.6 MB/s eta 0:00:01\r\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà       | 440 kB 11.6 MB/s eta 0:00:01\r\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã      | 450 kB 11.6 MB/s eta 0:00:01\r\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè     | 460 kB 11.6 MB/s eta 0:00:01\r\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ     | 471 kB 11.6 MB/s eta 0:00:01\r\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 481 kB 11.6 MB/s eta 0:00:01\r\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 491 kB 11.6 MB/s eta 0:00:01\r\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 501 kB 11.6 MB/s eta 0:00:01\r\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 512 kB 11.6 MB/s eta 0:00:01\r\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 522 kB 11.6 MB/s eta 0:00:01\r\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 532 kB 11.6 MB/s eta 0:00:01\r\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 542 kB 11.6 MB/s eta 0:00:01\r\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 552 kB 11.6 MB/s eta 0:00:01\r\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 562 kB 11.6 MB/s \n",
            "\u001b[?25h  Building wheel for imgaug (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Looking in links: https://download.pytorch.org/whl/torch_stable.html\n",
            "Collecting torch==1.8.0+cu111\n",
            "  Downloading https://download.pytorch.org/whl/cu111/torch-1.8.0%2Bcu111-cp37-cp37m-linux_x86_64.whl (1982.2 MB)\n",
            "\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå                  | 834.1 MB 2.2 MB/s eta 0:08:52tcmalloc: large alloc 1147494400 bytes == 0x561b539ee000 @  0x7f497abaf615 0x561b1a7764cc 0x561b1a85647a 0x561b1a7792ed 0x561b1a86ae1d 0x561b1a7ece99 0x561b1a7e79ee 0x561b1a77abda 0x561b1a7ecd00 0x561b1a7e79ee 0x561b1a77abda 0x561b1a7e9737 0x561b1a86bc66 0x561b1a7e8daf 0x561b1a86bc66 0x561b1a7e8daf 0x561b1a86bc66 0x561b1a7e8daf 0x561b1a77b039 0x561b1a7be409 0x561b1a779c52 0x561b1a7ecc25 0x561b1a7e79ee 0x561b1a77abda 0x561b1a7e9737 0x561b1a7e79ee 0x561b1a77abda 0x561b1a7e8915 0x561b1a77aafa 0x561b1a7e8c0d 0x561b1a7e79ee\n",
            "\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà               | 1055.7 MB 1.4 MB/s eta 0:10:44tcmalloc: large alloc 1434370048 bytes == 0x561b98044000 @  0x7f497abaf615 0x561b1a7764cc 0x561b1a85647a 0x561b1a7792ed 0x561b1a86ae1d 0x561b1a7ece99 0x561b1a7e79ee 0x561b1a77abda 0x561b1a7ecd00 0x561b1a7e79ee 0x561b1a77abda 0x561b1a7e9737 0x561b1a86bc66 0x561b1a7e8daf 0x561b1a86bc66 0x561b1a7e8daf 0x561b1a86bc66 0x561b1a7e8daf 0x561b1a77b039 0x561b1a7be409 0x561b1a779c52 0x561b1a7ecc25 0x561b1a7e79ee 0x561b1a77abda 0x561b1a7e9737 0x561b1a7e79ee 0x561b1a77abda 0x561b1a7e8915 0x561b1a77aafa 0x561b1a7e8c0d 0x561b1a7e79ee\n",
            "\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã          | 1336.2 MB 1.7 MB/s eta 0:06:27tcmalloc: large alloc 1792966656 bytes == 0x561b1ce76000 @  0x7f497abaf615 0x561b1a7764cc 0x561b1a85647a 0x561b1a7792ed 0x561b1a86ae1d 0x561b1a7ece99 0x561b1a7e79ee 0x561b1a77abda 0x561b1a7ecd00 0x561b1a7e79ee 0x561b1a77abda 0x561b1a7e9737 0x561b1a86bc66 0x561b1a7e8daf 0x561b1a86bc66 0x561b1a7e8daf 0x561b1a86bc66 0x561b1a7e8daf 0x561b1a77b039 0x561b1a7be409 0x561b1a779c52 0x561b1a7ecc25 0x561b1a7e79ee 0x561b1a77abda 0x561b1a7e9737 0x561b1a7e79ee 0x561b1a77abda 0x561b1a7e8915 0x561b1a77aafa 0x561b1a7e8c0d 0x561b1a7e79ee\n",
            "\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 1691.1 MB 1.4 MB/s eta 0:03:30tcmalloc: large alloc 2241208320 bytes == 0x561b87c5e000 @  0x7f497abaf615 0x561b1a7764cc 0x561b1a85647a 0x561b1a7792ed 0x561b1a86ae1d 0x561b1a7ece99 0x561b1a7e79ee 0x561b1a77abda 0x561b1a7ecd00 0x561b1a7e79ee 0x561b1a77abda 0x561b1a7e9737 0x561b1a86bc66 0x561b1a7e8daf 0x561b1a86bc66 0x561b1a7e8daf 0x561b1a86bc66 0x561b1a7e8daf 0x561b1a77b039 0x561b1a7be409 0x561b1a779c52 0x561b1a7ecc25 0x561b1a7e79ee 0x561b1a77abda 0x561b1a7e9737 0x561b1a7e79ee 0x561b1a77abda 0x561b1a7e8915 0x561b1a77aafa 0x561b1a7e8c0d 0x561b1a7e79ee\n",
            "\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1982.2 MB 1.4 MB/s eta 0:00:01tcmalloc: large alloc 1982251008 bytes == 0x561c0d5c0000 @  0x7f497abae1e7 0x561b1a7ac067 0x561b1a7764cc 0x561b1a85647a 0x561b1a7792ed 0x561b1a86ae1d 0x561b1a7ece99 0x561b1a7e79ee 0x561b1a77abda 0x561b1a7e8c0d 0x561b1a7e79ee 0x561b1a77abda 0x561b1a7e8c0d 0x561b1a7e79ee 0x561b1a77abda 0x561b1a7e8c0d 0x561b1a7e79ee 0x561b1a77abda 0x561b1a7e8c0d 0x561b1a7e79ee 0x561b1a77abda 0x561b1a7e8c0d 0x561b1a77aafa 0x561b1a7e8c0d 0x561b1a7e79ee 0x561b1a77abda 0x561b1a7e9737 0x561b1a7e79ee 0x561b1a77abda 0x561b1a7e9737 0x561b1a7e79ee\n",
            "tcmalloc: large alloc 2477817856 bytes == 0x561c8382c000 @  0x7f497abaf615 0x561b1a7764cc 0x561b1a85647a 0x561b1a7792ed 0x561b1a86ae1d 0x561b1a7ece99 0x561b1a7e79ee 0x561b1a77abda 0x561b1a7e8c0d 0x561b1a7e79ee 0x561b1a77abda 0x561b1a7e8c0d 0x561b1a7e79ee 0x561b1a77abda 0x561b1a7e8c0d 0x561b1a7e79ee 0x561b1a77abda 0x561b1a7e8c0d 0x561b1a7e79ee 0x561b1a77abda 0x561b1a7e8c0d 0x561b1a77aafa 0x561b1a7e8c0d 0x561b1a7e79ee 0x561b1a77abda 0x561b1a7e9737 0x561b1a7e79ee 0x561b1a77abda 0x561b1a7e9737 0x561b1a7e79ee 0x561b1a77b271\n",
            "\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1982.2 MB 1.1 kB/s \n",
            "\u001b[?25hCollecting torchvision==0.9.0+cu111\n",
            "  Downloading https://download.pytorch.org/whl/cu111/torchvision-0.9.0%2Bcu111-cp37-cp37m-linux_x86_64.whl (17.6 MB)\n",
            "\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 17.6 MB 49.1 MB/s \n",
            "\u001b[?25hCollecting torchtext==0.9.0\n",
            "  Downloading torchtext-0.9.0-cp37-cp37m-manylinux1_x86_64.whl (7.1 MB)\n",
            "\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7.1 MB 12.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torch==1.8.0+cu111) (1.19.5)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch==1.8.0+cu111) (3.10.0.2)\n",
            "Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.7/dist-packages (from torchvision==0.9.0+cu111) (7.1.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from torchtext==0.9.0) (2.23.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from torchtext==0.9.0) (4.62.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext==0.9.0) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext==0.9.0) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext==0.9.0) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext==0.9.0) (2021.10.8)\n",
            "Installing collected packages: torch, torchvision, torchtext\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 1.10.0+cu111\n",
            "    Uninstalling torch-1.10.0+cu111:\n",
            "      Successfully uninstalled torch-1.10.0+cu111\n",
            "  Attempting uninstall: torchvision\n",
            "    Found existing installation: torchvision 0.11.1+cu111\n",
            "    Uninstalling torchvision-0.11.1+cu111:\n",
            "      Successfully uninstalled torchvision-0.11.1+cu111\n",
            "  Attempting uninstall: torchtext\n",
            "    Found existing installation: torchtext 0.11.0\n",
            "    Uninstalling torchtext-0.11.0:\n",
            "      Successfully uninstalled torchtext-0.11.0\n",
            "Successfully installed torch-1.8.0+cu111 torchtext-0.9.0 torchvision-0.9.0+cu111\n",
            "\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 215 kB 11.9 MB/s \n",
            "\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 11.2 MB 48.0 MB/s \n",
            "\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3.2 MB 30.6 MB/s \n",
            "\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3.3 MB 39.8 MB/s \n",
            "\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4.1 MB 25.2 MB/s \n",
            "\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 57 kB 4.4 MB/s \n",
            "\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 873 kB 38.0 MB/s \n",
            "\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 101 kB 12.2 MB/s \n",
            "\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 55 kB 4.5 MB/s \n",
            "\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1.3 MB 38.2 MB/s \n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "# @title Install Dependencies\n",
        "\n",
        "!pip install imgaug==0.2.5 --quiet \n",
        "!pip install ivadomed --quiet \n",
        "\n",
        "%load_ext tensorboard"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yv-G9XObSVm0"
      },
      "source": [
        "### Download the Dataset\n",
        "\n",
        "We will be using a publicly available dataset consisting of the MRI data of the spinal cord. This dataset is a subset of the [spine-generic multi-center dataset](https://github.com/spine-generic/data-multi-subject) and has been pre-processed to facilitate training/testing of a new model. Namely, for each subject, all six contrasts were co-registered together. Semi-manual cord segmentation for all modalities and manual cerebrospinal fluid labels for T2w modality were created. More details can be found [here](https://github.com/ivadomed/ivadomed/blob/master/dev/prepare_data/README.md).\n",
        "\n",
        "In addition to the MRI data, this sample dataset also includes a trained model for spinal cord segmentation. The size of the dataset is about 490MB. Please run the following cell to download the dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FYHpujawOElC",
        "outputId": "2447440e-3e75-4025-cf8e-e63871558dbf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[32m2021-11-18 16:40:49.160\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mivadomed.utils\u001b[0m:\u001b[36minit_ivadomed\u001b[0m:\u001b[36m408\u001b[0m - \u001b[1m\n",
            "ivadomed (2.9.0)\n",
            "\u001b[0m\n",
            "Trying URL: https://github.com/ivadomed/data_example_spinegeneric/archive/r20200825.zip\n",
            "Downloading: data_example_spinegeneric-r20200825.zip\n",
            "Unzip data to: /tmp/tmpzfsxoabq\n",
            "Removing temporary folders...\n",
            "Folder Created: /content/data_example_spinegeneric\n",
            "--2021-11-18 16:41:31--  https://raw.githubusercontent.com/ivadomed/ivadomed/master/ivadomed/config/config.json\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.110.133, 185.199.109.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 3699 (3.6K) [text/plain]\n",
            "Saving to: ‚Äòconfig.json‚Äô\n",
            "\n",
            "config.json         100%[===================>]   3.61K  --.-KB/s    in 0s      \n",
            "\n",
            "2021-11-18 16:41:31 (33.5 MB/s) - ‚Äòconfig.json‚Äô saved [3699/3699]\n",
            "\n",
            "--2021-11-18 16:41:31--  http://./content\n",
            "Resolving . (.)... failed: No address associated with hostname.\n",
            "wget: unable to resolve host address ‚Äò.‚Äô\n",
            "FINISHED --2021-11-18 16:41:31--\n",
            "Total wall clock time: 0.2s\n",
            "Downloaded: 1 files, 3.6K in 0s (33.5 MB/s)\n"
          ]
        }
      ],
      "source": [
        "# @title Run Me to Download the Dataset!\n",
        "\n",
        "# download the dataset\n",
        "!ivadomed_download_data -d data_example_spinegeneric"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zMJcEJLXTpEo"
      },
      "source": [
        "### Configuration File\n",
        "In `ivadomed`, the training is orchestrated by a configuration file. In short, it is the JSON file that contains all the parameters used for loading the data, training and evaluating the model. An in-depth documentation on how to use the configuration file is available [here](https://ivadomed.org/configuration_file.html). Some examples of configuration files are available in the `ivadomed/config/` folder [here](https://github.com/ivadomed/ivadomed/tree/master/ivadomed/config).\n",
        "\n",
        "In this tutorial, we will be using the configuration file: `ivadomed/config/config.json`. This is already downloaded for you and can be seen under Colab's `Files` (üìÅ) tab on the left.\n",
        "\n",
        "Open this file and follow on for more information on some of the key parameters for performing the one-class 2D segmentation:\n",
        "\n",
        "\n",
        "1. `command` - The task to perform. This can either be \"train\" or \"test\". For training the model, we first set this key to \"train\".\n",
        "```json\n",
        "    \"command\": \"train\"\n",
        "```\n",
        "\n",
        "2. `path_output` - The name of the folder that will be populated by the output files (e.g. the trained model, predictions, results, etc.)\n",
        "```json\n",
        "    \"path_output\": \"spineGeneric\"\n",
        "```\n",
        "\n",
        "3. `loader_parameters:path_data` - The location of the dataset. As discussed in [Data](https://ivadomed.org/data.html), the dataset must conform to the BIDS standard. This value can be modified so as to point to the correct location of the downloaded dataset.\n",
        "```json\n",
        "    path_data: \"data_example_spinegeneric\"\n",
        "```\n",
        "\n",
        "4. `loader_parameters:target_suffix` - The suffix for the name of the ground truth (GT) segmentation file. The GT is located under the `DATASET/derivatives/labels` folder. For this tutorial, the suffix is `_seg-manual`.\n",
        "```json\n",
        "    \"target_suffix\": [\"_seg_manual\"]\n",
        "```\n",
        "\n",
        "5. `loader_parameters:contrast_params` - A dicitionary containing the contrasts of interest.\n",
        "```json\n",
        "    \"contrast params\": {\n",
        "        \"training_validation\": [\"T1w\", \"T2w\", \"T2star\"],\n",
        "        \"testing\": [\"T1w\", \"T2w\", \"T2star\"],\n",
        "        \"balance\": {}\n",
        "    }\n",
        "```\n",
        "\n",
        "6. `loader_parameters:slice_axis` - The orientation of the 2D slice to use with the model.\n",
        "```json\n",
        "    \"slice_axis\": \"axial\"\n",
        "```\n",
        "\n",
        "7. `loader_parameters:multichannel` - Turn on/off multi-channel training. If true, each sample has several channels, where each channel is an image contrast. If false, only one image contrast is used per sample.\n",
        "```json\n",
        "    \"multichannel\": false\n",
        "```\n",
        "\n",
        "‚ö†Ô∏è **Note**: The multichannel approach requires that for each subject, the image contrasts are co-registered. This implies that a ground truth segmentation is aligned with all contrasts, for a given subject. In this tutorial, only a single channel will be used.\n",
        "\n",
        "8. `training_time:num_epochs` - The maximum number of epochs that will be run during training. Each epoch is composed of a training part and an validation part. It should be a positive integer.\n",
        "```json\n",
        "    \"num_epochs\": 100\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nbi9YV9j4E3Q"
      },
      "source": [
        "### Modify the Config File\n",
        "\n",
        "Now that we know how the config file is structured, open the `config.json` file under the \"Files\" tab on the left. This should let you edit the contents of the json file as mentioned above. Change the following parameters:\n",
        "\n",
        "1. `\"path_output\": \"spineGeneric_gpu\"`  (just to differentiate the results obtained from the GPU)\n",
        "2. `\"debugging\": true`     (to visualize training on Tensorboard)\n",
        "3. `\"num_epochs\": 20`      (running on a few epochs for the purpose of this tutorial)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rlPGhRMrh051"
      },
      "source": [
        "### Train the Model\n",
        "\n",
        "Once the config file is saved and ready, the following command is used for training:\n",
        "```shell\n",
        "    ivadomed --train -c config.json --path-data path/to/bids/data --path-output path/to/output/directory\n",
        "```\n",
        "\n",
        "If the `--path_data` and `--path_output` keys are already mentioned in the config file then they do not need to be specified again. The **shorter command** shown below can be run instead: \n",
        "```shell\n",
        "    ivadomed --train -c config.json\n",
        "```\n",
        "\n",
        "‚ö†Ô∏è **Note**: If a compatible GPU is available, it will be used by default (see the `\"gpu_id\"` key in the config file). Otherwise, training will use the CPU, which will take a prohibitively long computational time (several hours).\n",
        "\n",
        "The main parameters of the training scheme and model will be displayed on the terminal, followed by the loss value on training and validation sets at every epoch. To know more about the meaning of each parameter, go to the [Configuration File](https://ivadomed.org/configuration_file.html). The value of the loss should decrease during the training.\n",
        "\n",
        "After 20 epochs (see \"num_epochs\" in the configuration file), the Dice score on the validation set should be ~0.9."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pSnnnu6SA_0-",
        "outputId": "6f86c0dc-b8ce-410f-8e55-e09eb4dd7f63"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[32m2021-11-18 16:48:46.573\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mivadomed.utils\u001b[0m:\u001b[36minit_ivadomed\u001b[0m:\u001b[36m408\u001b[0m - \u001b[1m\n",
            "ivadomed (2.9.0)\n",
            "\u001b[0m\n",
            "\u001b[32m2021-11-18 16:48:46.576\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mivadomed.config_manager\u001b[0m:\u001b[36m_display_differing_keys\u001b[0m:\u001b[36m150\u001b[0m - \u001b[1mAdding the following keys to the configuration file\u001b[0m\n",
            "\u001b[32m2021-11-18 16:48:46.576\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mivadomed.config_manager\u001b[0m:\u001b[36mdeep_dict_compare\u001b[0m:\u001b[36m43\u001b[0m - \u001b[1m    log_file: log\u001b[0m\n",
            "\u001b[32m2021-11-18 16:48:46.576\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mivadomed.config_manager\u001b[0m:\u001b[36mdeep_dict_compare\u001b[0m:\u001b[36m43\u001b[0m - \u001b[1m    loader_parameters: is_input_dropout: False\u001b[0m\n",
            "\u001b[32m2021-11-18 16:48:46.576\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mivadomed.config_manager\u001b[0m:\u001b[36mdeep_dict_compare\u001b[0m:\u001b[36m43\u001b[0m - \u001b[1m    default_model: is_2d: True\u001b[0m\n",
            "\u001b[32m2021-11-18 16:48:46.576\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mivadomed.config_manager\u001b[0m:\u001b[36m_display_differing_keys\u001b[0m:\u001b[36m152\u001b[0m - \u001b[1m\n",
            "\u001b[0m\n",
            "\u001b[32m2021-11-18 16:48:46.576\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mivadomed.utils\u001b[0m:\u001b[36mget_path_output\u001b[0m:\u001b[36m371\u001b[0m - \u001b[1mCLI flag --path-output not used to specify output directory. Will check config file for directory...\u001b[0m\n",
            "\u001b[32m2021-11-18 16:48:46.577\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mivadomed.utils\u001b[0m:\u001b[36mget_path_data\u001b[0m:\u001b[36m383\u001b[0m - \u001b[1mCLI flag --path-data not used to specify BIDS data directory. Will check config file for directory...\u001b[0m\n",
            "\u001b[32m2021-11-18 16:48:46.577\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mivadomed.main\u001b[0m:\u001b[36mset_output_path\u001b[0m:\u001b[36m195\u001b[0m - \u001b[1mCreating output path: spineGeneric_gpu\u001b[0m\n",
            "\u001b[32m2021-11-18 16:48:46.730\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mivadomed.utils\u001b[0m:\u001b[36mdefine_device\u001b[0m:\u001b[36m135\u001b[0m - \u001b[1mUsing GPU ID 0\u001b[0m\n",
            "\u001b[32m2021-11-18 16:48:46.731\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mivadomed.utils\u001b[0m:\u001b[36mdisplay_selected_model_spec\u001b[0m:\u001b[36m145\u001b[0m - \u001b[1mSelected architecture: Unet, with the following parameters:\u001b[0m\n",
            "\u001b[32m2021-11-18 16:48:46.732\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mivadomed.utils\u001b[0m:\u001b[36mdisplay_selected_model_spec\u001b[0m:\u001b[36m148\u001b[0m - \u001b[1m\tdropout_rate: 0.3\u001b[0m\n",
            "\u001b[32m2021-11-18 16:48:46.732\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mivadomed.utils\u001b[0m:\u001b[36mdisplay_selected_model_spec\u001b[0m:\u001b[36m148\u001b[0m - \u001b[1m\tbn_momentum: 0.1\u001b[0m\n",
            "\u001b[32m2021-11-18 16:48:46.732\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mivadomed.utils\u001b[0m:\u001b[36mdisplay_selected_model_spec\u001b[0m:\u001b[36m148\u001b[0m - \u001b[1m\tdepth: 3\u001b[0m\n",
            "\u001b[32m2021-11-18 16:48:46.732\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mivadomed.utils\u001b[0m:\u001b[36mdisplay_selected_model_spec\u001b[0m:\u001b[36m148\u001b[0m - \u001b[1m\tis_2d: True\u001b[0m\n",
            "\u001b[32m2021-11-18 16:48:46.733\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mivadomed.utils\u001b[0m:\u001b[36mdisplay_selected_model_spec\u001b[0m:\u001b[36m148\u001b[0m - \u001b[1m\tfinal_activation: sigmoid\u001b[0m\n",
            "\u001b[32m2021-11-18 16:48:46.733\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mivadomed.utils\u001b[0m:\u001b[36mdisplay_selected_model_spec\u001b[0m:\u001b[36m148\u001b[0m - \u001b[1m\tfolder_name: my_model\u001b[0m\n",
            "\u001b[32m2021-11-18 16:48:46.733\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mivadomed.utils\u001b[0m:\u001b[36mdisplay_selected_model_spec\u001b[0m:\u001b[36m148\u001b[0m - \u001b[1m\tin_channel: 1\u001b[0m\n",
            "\u001b[32m2021-11-18 16:48:46.733\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mivadomed.utils\u001b[0m:\u001b[36mdisplay_selected_model_spec\u001b[0m:\u001b[36m148\u001b[0m - \u001b[1m\tout_channel: 1\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/bids/config.py:40: FutureWarning: Setting 'extension_initial_dot' will be removed in pybids 0.16.\n",
            "  FutureWarning)\n",
            "\u001b[32m2021-11-18 16:48:46.744\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mivadomed.loader.bids_dataframe\u001b[0m:\u001b[36mwrite_derivatives_dataset_description\u001b[0m:\u001b[36m304\u001b[0m - \u001b[33m\u001b[1m/content/data_example_spinegeneric/derivatives/dataset_description.json not found. Please ensure a full path is specified in the configuration file. Will attempt to create a place holder description file for now at/content/data_example_spinegeneric/derivatives/dataset_description.json.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/bids/layout/validation.py:149: UserWarning: The PipelineDescription field was superseded by GeneratedBy in BIDS 1.4.0. You can use ``pybids upgrade`` to update your derivative dataset.\n",
            "  warnings.warn(\"The PipelineDescription field was superseded \"\n",
            "\u001b[32m2021-11-18 16:48:48.117\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mivadomed.loader.bids_dataframe\u001b[0m:\u001b[36msave\u001b[0m:\u001b[36m289\u001b[0m - \u001b[1mDataframe has been saved in spineGeneric_gpu/bids_dataframe.csv.\u001b[0m\n",
            "\u001b[32m2021-11-18 16:48:48.124\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mivadomed.loader.utils\u001b[0m:\u001b[36msplit_dataset\u001b[0m:\u001b[36m102\u001b[0m - \u001b[33m\u001b[1mAfter splitting: train, validation and test fractions are respectively 0.6, 0.2 and 0.2 of participant_id.\u001b[0m\n",
            "\u001b[32m2021-11-18 16:48:49.076\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mivadomed.utils\u001b[0m:\u001b[36mdisplay_selected_transfoms\u001b[0m:\u001b[36m158\u001b[0m - \u001b[1mSelected transformations for the ['training'] dataset:\u001b[0m\n",
            "\u001b[32m2021-11-18 16:48:49.076\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mivadomed.utils\u001b[0m:\u001b[36mdisplay_selected_transfoms\u001b[0m:\u001b[36m160\u001b[0m - \u001b[1m\tResample: {'hspace': 0.75, 'wspace': 0.75, 'dspace': 1}\u001b[0m\n",
            "\u001b[32m2021-11-18 16:48:49.077\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mivadomed.utils\u001b[0m:\u001b[36mdisplay_selected_transfoms\u001b[0m:\u001b[36m160\u001b[0m - \u001b[1m\tCenterCrop: {'size': [128, 128]}\u001b[0m\n",
            "\u001b[32m2021-11-18 16:48:49.077\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mivadomed.utils\u001b[0m:\u001b[36mdisplay_selected_transfoms\u001b[0m:\u001b[36m160\u001b[0m - \u001b[1m\tRandomAffine: {'degrees': 5, 'scale': [0.1, 0.1], 'translate': [0.03, 0.03], 'applied_to': ['im', 'gt']}\u001b[0m\n",
            "\u001b[32m2021-11-18 16:48:49.077\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mivadomed.utils\u001b[0m:\u001b[36mdisplay_selected_transfoms\u001b[0m:\u001b[36m160\u001b[0m - \u001b[1m\tElasticTransform: {'alpha_range': [28.0, 30.0], 'sigma_range': [3.5, 4.5], 'p': 0.1, 'applied_to': ['im', 'gt']}\u001b[0m\n",
            "\u001b[32m2021-11-18 16:48:49.077\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mivadomed.utils\u001b[0m:\u001b[36mdisplay_selected_transfoms\u001b[0m:\u001b[36m160\u001b[0m - \u001b[1m\tNormalizeInstance: {'applied_to': ['im']}\u001b[0m\n",
            "\u001b[32m2021-11-18 16:48:49.078\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mivadomed.utils\u001b[0m:\u001b[36mdisplay_selected_transfoms\u001b[0m:\u001b[36m158\u001b[0m - \u001b[1mSelected transformations for the ['validation'] dataset:\u001b[0m\n",
            "\u001b[32m2021-11-18 16:48:49.078\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mivadomed.utils\u001b[0m:\u001b[36mdisplay_selected_transfoms\u001b[0m:\u001b[36m160\u001b[0m - \u001b[1m\tResample: {'hspace': 0.75, 'wspace': 0.75, 'dspace': 1}\u001b[0m\n",
            "\u001b[32m2021-11-18 16:48:49.078\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mivadomed.utils\u001b[0m:\u001b[36mdisplay_selected_transfoms\u001b[0m:\u001b[36m160\u001b[0m - \u001b[1m\tCenterCrop: {'size': [128, 128]}\u001b[0m\n",
            "\u001b[32m2021-11-18 16:48:49.078\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mivadomed.utils\u001b[0m:\u001b[36mdisplay_selected_transfoms\u001b[0m:\u001b[36m160\u001b[0m - \u001b[1m\tNormalizeInstance: {'applied_to': ['im']}\u001b[0m\n",
            "Loading dataset: 100% 6/6 [00:00<00:00, 167.01it/s]\n",
            "\u001b[32m2021-11-18 16:48:55.653\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mivadomed.loader.loader\u001b[0m:\u001b[36mload_dataset\u001b[0m:\u001b[36m114\u001b[0m - \u001b[1mLoaded 92 axial slices for the validation set.\u001b[0m\n",
            "Loading dataset: 100% 17/17 [00:00<00:00, 90.33it/s]\n",
            "\u001b[32m2021-11-18 16:49:13.834\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mivadomed.loader.loader\u001b[0m:\u001b[36mload_dataset\u001b[0m:\u001b[36m114\u001b[0m - \u001b[1mLoaded 276 axial slices for the training set.\u001b[0m\n",
            "\u001b[32m2021-11-18 16:49:13.834\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mivadomed.main\u001b[0m:\u001b[36mcreate_path_model\u001b[0m:\u001b[36m78\u001b[0m - \u001b[1mCreating model directory: spineGeneric_gpu/my_model\u001b[0m\n",
            "\u001b[32m2021-11-18 16:49:21.176\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mivadomed.training\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m99\u001b[0m - \u001b[1mInitialising model's weights from scratch.\u001b[0m\n",
            "\u001b[32m2021-11-18 16:49:31.783\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mivadomed.training\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m115\u001b[0m - \u001b[1mScheduler parameters: {'name': 'CosineAnnealingLR', 'base_lr': 1e-05, 'max_lr': 0.01}\u001b[0m\n",
            "\u001b[32m2021-11-18 16:49:31.784\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mivadomed.training\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m135\u001b[0m - \u001b[1mSelected Loss: DiceLoss\u001b[0m\n",
            "\u001b[32m2021-11-18 16:49:31.784\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mivadomed.training\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m137\u001b[0m - \u001b[1m\twith the parameters: []\u001b[0m\n",
            "Training:   7% 1/15 [00:00<?, ?it/s]\u001b[32m2021-11-18 16:49:55.232\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mivadomed.training\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m206\u001b[0m - \u001b[1mEpoch 1 training loss: -0.0421.\u001b[0m\n",
            "Epoch 1 training loss: -0.0421.\n",
            "Training:   7% 1/15 [00:23<?, ?it/s]\u001b[32m2021-11-18 16:50:02.050\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mivadomed.training\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m278\u001b[0m - \u001b[1mEpoch 1 validation loss: -0.0459.\u001b[0m\n",
            "\u001b[32m2021-11-18 16:50:02.050\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mivadomed.training\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m282\u001b[0m - \u001b[1mEpoch 1 took 30.27 seconds.\u001b[0m\n",
            "Training:  13% 2/15 [00:30<06:35, 30.44s/it]\u001b[32m2021-11-18 16:50:10.475\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mivadomed.training\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m206\u001b[0m - \u001b[1mEpoch 2 training loss: -0.0831.\u001b[0m\n",
            "Epoch 2 training loss: -0.0831.\n",
            "Training:  13% 2/15 [00:38<06:35, 30.44s/it]\u001b[32m2021-11-18 16:50:15.117\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mivadomed.training\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m278\u001b[0m - \u001b[1mEpoch 2 validation loss: -0.0604.\u001b[0m\n",
            "\u001b[32m2021-11-18 16:50:15.118\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mivadomed.training\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m282\u001b[0m - \u001b[1mEpoch 2 took 12.89 seconds.\u001b[0m\n",
            "Training:  20% 3/15 [00:44<04:07, 20.58s/it]\u001b[32m2021-11-18 16:50:24.151\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mivadomed.training\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m206\u001b[0m - \u001b[1mEpoch 3 training loss: -0.1422.\u001b[0m\n",
            "Epoch 3 training loss: -0.1422.\n",
            "Training:  20% 3/15 [00:52<04:07, 20.58s/it]\u001b[32m2021-11-18 16:50:28.672\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mivadomed.training\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m278\u001b[0m - \u001b[1mEpoch 3 validation loss: -0.2376.\u001b[0m\n",
            "\u001b[32m2021-11-18 16:50:28.673\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mivadomed.training\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m282\u001b[0m - \u001b[1mEpoch 3 took 12.76 seconds.\u001b[0m\n",
            "Training:  27% 4/15 [00:57<03:08, 17.10s/it]\u001b[32m2021-11-18 16:50:37.038\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mivadomed.training\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m206\u001b[0m - \u001b[1mEpoch 4 training loss: -0.2086.\u001b[0m\n",
            "Epoch 4 training loss: -0.2086.\n",
            "Training:  27% 4/15 [01:05<03:08, 17.10s/it]\u001b[32m2021-11-18 16:50:41.532\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mivadomed.training\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m278\u001b[0m - \u001b[1mEpoch 4 validation loss: -0.2349.\u001b[0m\n",
            "\u001b[32m2021-11-18 16:50:41.534\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mivadomed.training\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m282\u001b[0m - \u001b[1mEpoch 4 took 12.67 seconds.\u001b[0m\n",
            "Training:  33% 5/15 [01:09<02:33, 15.35s/it]\u001b[32m2021-11-18 16:50:49.700\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mivadomed.training\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m206\u001b[0m - \u001b[1mEpoch 5 training loss: -0.3052.\u001b[0m\n",
            "Epoch 5 training loss: -0.3052.\n",
            "Training:  33% 5/15 [01:17<02:33, 15.35s/it]\u001b[32m2021-11-18 16:50:54.145\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mivadomed.training\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m278\u001b[0m - \u001b[1mEpoch 5 validation loss: -0.1016.\u001b[0m\n",
            "\u001b[32m2021-11-18 16:50:54.147\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mivadomed.training\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m282\u001b[0m - \u001b[1mEpoch 5 took 12.61 seconds.\u001b[0m\n",
            "Training:  40% 6/15 [01:22<02:09, 14.36s/it]\u001b[32m2021-11-18 16:51:02.305\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mivadomed.training\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m206\u001b[0m - \u001b[1mEpoch 6 training loss: -0.4290.\u001b[0m\n",
            "Epoch 6 training loss: -0.4290.\n",
            "Training:  40% 6/15 [01:30<02:09, 14.36s/it]\u001b[32m2021-11-18 16:51:06.736\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mivadomed.training\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m278\u001b[0m - \u001b[1mEpoch 6 validation loss: -0.2316.\u001b[0m\n",
            "\u001b[32m2021-11-18 16:51:06.738\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mivadomed.training\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m282\u001b[0m - \u001b[1mEpoch 6 took 12.59 seconds.\u001b[0m\n",
            "Training:  47% 7/15 [01:34<01:50, 13.76s/it]\u001b[32m2021-11-18 16:51:14.865\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mivadomed.training\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m206\u001b[0m - \u001b[1mEpoch 7 training loss: -0.5527.\u001b[0m\n",
            "Epoch 7 training loss: -0.5527.\n",
            "Training:  47% 7/15 [01:43<01:50, 13.76s/it]\u001b[32m2021-11-18 16:51:19.319\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mivadomed.training\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m278\u001b[0m - \u001b[1mEpoch 7 validation loss: -0.5790.\u001b[0m\n",
            "\u001b[32m2021-11-18 16:51:19.320\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mivadomed.training\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m282\u001b[0m - \u001b[1mEpoch 7 took 12.58 seconds.\u001b[0m\n",
            "Training:  53% 8/15 [01:47<01:34, 13.44s/it]\u001b[32m2021-11-18 16:51:27.657\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mivadomed.training\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m206\u001b[0m - \u001b[1mEpoch 8 training loss: -0.6147.\u001b[0m\n",
            "Epoch 8 training loss: -0.6147.\n",
            "Training:  53% 8/15 [01:55<01:34, 13.44s/it]\u001b[32m2021-11-18 16:51:32.099\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mivadomed.training\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m278\u001b[0m - \u001b[1mEpoch 8 validation loss: -0.7416.\u001b[0m\n",
            "\u001b[32m2021-11-18 16:51:32.101\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mivadomed.training\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m282\u001b[0m - \u001b[1mEpoch 8 took 12.58 seconds.\u001b[0m\n",
            "Training:  60% 9/15 [02:00<01:19, 13.23s/it]\u001b[32m2021-11-18 16:51:40.425\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mivadomed.training\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m206\u001b[0m - \u001b[1mEpoch 9 training loss: -0.7200.\u001b[0m\n",
            "Epoch 9 training loss: -0.7200.\n",
            "Training:  60% 9/15 [02:08<01:19, 13.23s/it]\u001b[32m2021-11-18 16:51:44.842\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mivadomed.training\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m278\u001b[0m - \u001b[1mEpoch 9 validation loss: -0.7794.\u001b[0m\n",
            "\u001b[32m2021-11-18 16:51:44.844\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mivadomed.training\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m282\u001b[0m - \u001b[1mEpoch 9 took 12.55 seconds.\u001b[0m\n",
            "Training:  67% 10/15 [02:13<01:05, 13.08s/it]\u001b[32m2021-11-18 16:51:53.171\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mivadomed.training\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m206\u001b[0m - \u001b[1mEpoch 10 training loss: -0.7703.\u001b[0m\n",
            "Epoch 10 training loss: -0.7703.\n",
            "Training:  67% 10/15 [02:21<01:05, 13.08s/it]\u001b[32m2021-11-18 16:51:57.658\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mivadomed.training\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m278\u001b[0m - \u001b[1mEpoch 10 validation loss: -0.8687.\u001b[0m\n",
            "\u001b[32m2021-11-18 16:51:57.660\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mivadomed.training\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m282\u001b[0m - \u001b[1mEpoch 10 took 12.63 seconds.\u001b[0m\n",
            "Training:  73% 11/15 [02:26<00:51, 12.99s/it]\u001b[32m2021-11-18 16:52:05.973\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mivadomed.training\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m206\u001b[0m - \u001b[1mEpoch 11 training loss: -0.8012.\u001b[0m\n",
            "Epoch 11 training loss: -0.8012.\n",
            "Training:  73% 11/15 [02:34<00:51, 12.99s/it]\u001b[32m2021-11-18 16:52:10.359\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mivadomed.training\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m278\u001b[0m - \u001b[1mEpoch 11 validation loss: -0.8765.\u001b[0m\n",
            "\u001b[32m2021-11-18 16:52:10.361\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mivadomed.training\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m282\u001b[0m - \u001b[1mEpoch 11 took 12.52 seconds.\u001b[0m\n",
            "Training:  80% 12/15 [02:38<00:38, 12.91s/it]\u001b[32m2021-11-18 16:52:18.696\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mivadomed.training\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m206\u001b[0m - \u001b[1mEpoch 12 training loss: -0.8184.\u001b[0m\n",
            "Epoch 12 training loss: -0.8184.\n",
            "Training:  80% 12/15 [02:46<00:38, 12.91s/it]\u001b[32m2021-11-18 16:52:23.114\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mivadomed.training\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m278\u001b[0m - \u001b[1mEpoch 12 validation loss: -0.8688.\u001b[0m\n",
            "\u001b[32m2021-11-18 16:52:23.115\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mivadomed.training\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m282\u001b[0m - \u001b[1mEpoch 12 took 12.57 seconds.\u001b[0m\n",
            "Training:  87% 13/15 [02:51<00:25, 12.80s/it]\u001b[32m2021-11-18 16:52:31.234\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mivadomed.training\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m206\u001b[0m - \u001b[1mEpoch 13 training loss: -0.8304.\u001b[0m\n",
            "Epoch 13 training loss: -0.8304.\n",
            "Training:  87% 13/15 [02:59<00:25, 12.80s/it]\u001b[32m2021-11-18 16:52:35.680\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mivadomed.training\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m278\u001b[0m - \u001b[1mEpoch 13 validation loss: -0.8945.\u001b[0m\n",
            "\u001b[32m2021-11-18 16:52:35.682\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mivadomed.training\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m282\u001b[0m - \u001b[1mEpoch 13 took 12.57 seconds.\u001b[0m\n",
            "Training:  93% 14/15 [03:04<00:12, 12.79s/it]\u001b[32m2021-11-18 16:52:43.987\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mivadomed.training\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m206\u001b[0m - \u001b[1mEpoch 14 training loss: -0.8368.\u001b[0m\n",
            "Epoch 14 training loss: -0.8368.\n",
            "Training:  93% 14/15 [03:12<00:12, 12.79s/it]\u001b[32m2021-11-18 16:52:48.434\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mivadomed.training\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m278\u001b[0m - \u001b[1mEpoch 14 validation loss: -0.8962.\u001b[0m\n",
            "\u001b[32m2021-11-18 16:52:48.436\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mivadomed.training\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m282\u001b[0m - \u001b[1mEpoch 14 took 12.57 seconds.\u001b[0m\n",
            "Training: 100% 15/15 [03:16<00:00, 12.78s/it]\u001b[32m2021-11-18 16:52:56.770\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mivadomed.training\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m206\u001b[0m - \u001b[1mEpoch 15 training loss: -0.8330.\u001b[0m\n",
            "Epoch 15 training loss: -0.8330.\n",
            "Training: 100% 15/15 [03:24<00:00, 12.78s/it]\u001b[32m2021-11-18 16:53:01.147\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mivadomed.training\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m278\u001b[0m - \u001b[1mEpoch 15 validation loss: -0.8794.\u001b[0m\n",
            "\u001b[32m2021-11-18 16:53:01.148\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mivadomed.training\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m282\u001b[0m - \u001b[1mEpoch 15 took 12.53 seconds.\u001b[0m\n",
            "Training: 16it [03:29, 13.96s/it]\n",
            "\u001b[32m2021-11-18 16:53:02.006\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mivadomed.training\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m353\u001b[0m - \u001b[1mbegin 16:49:31| End 16:53:02| duration 0:03:30.222237\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "# @title Run me to start the training!\n",
        "\n",
        "# train the model\n",
        "!ivadomed --train -c config.json"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VfF4JBRfWCmH",
        "outputId": "e4a22308-069e-448d-bbf5-760af04eccd2"
      },
      "outputs": [
        {
          "data": {
            "application/javascript": "\n        (async () => {\n            const url = new URL(await google.colab.kernel.proxyPort(6006, {'cache': true}));\n            url.searchParams.set('tensorboardColab', 'true');\n            const iframe = document.createElement('iframe');\n            iframe.src = url;\n            iframe.setAttribute('width', '100%');\n            iframe.setAttribute('height', '800');\n            iframe.setAttribute('frameborder', 0);\n            document.body.appendChild(iframe);\n        })();\n    ",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# @title Visualize loss curves on Tensorboard\n",
        "\n",
        "# see the training progress on Tensorboard\n",
        "# note that the output folder is the same \"path_output\" folder used in the config file\n",
        "%tensorboard --logdir spineGeneric_gpu"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WUZOIO8BukmF"
      },
      "source": [
        "### Evaluate the Model\n",
        "\n",
        "To test the trained model on the testing subset of the dataset and compute the evaluation metrics, run the following command: \n",
        "```shell\n",
        "    ivadomed --test -c config.json --path-data path/to/bids/data --path-output path/to/output/directory\n",
        "```\n",
        "\n",
        "Again, if `--path_data` and `--path_output` are already mentioned in the config file, use the command below instead:\n",
        "```shell\n",
        "    ivadomed --test -c config.json\n",
        "```\n",
        "\n",
        "The model‚Äôs parameters will be displayed in the cell's output, followed by a preview of the results for each image. The resulting segmentation is saved for each image in the `<PATH_TO_OUT_DIR>/pred_masks` while a csv file, saved in `<PATH_TO_OUT_DIR>/results_eval/evaluation_3Dmetrics.csv`, contains all the evaluation metrics. For more details on the evaluation metrics, see `ivadomed.metrics` [here](https://ivadomed.org/api_ref.html#module-ivadomed.metrics)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PkUga7e_Mdht",
        "outputId": "18491925-2ca4-4850-d569-6ca1a7412a83"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[32m2021-11-18 16:55:56.370\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mivadomed.utils\u001b[0m:\u001b[36minit_ivadomed\u001b[0m:\u001b[36m408\u001b[0m - \u001b[1m\n",
            "ivadomed (2.9.0)\n",
            "\u001b[0m\n",
            "\u001b[32m2021-11-18 16:55:56.373\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mivadomed.config_manager\u001b[0m:\u001b[36m_display_differing_keys\u001b[0m:\u001b[36m150\u001b[0m - \u001b[1mAdding the following keys to the configuration file\u001b[0m\n",
            "\u001b[32m2021-11-18 16:55:56.373\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mivadomed.config_manager\u001b[0m:\u001b[36mdeep_dict_compare\u001b[0m:\u001b[36m43\u001b[0m - \u001b[1m    log_file: log\u001b[0m\n",
            "\u001b[32m2021-11-18 16:55:56.373\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mivadomed.config_manager\u001b[0m:\u001b[36mdeep_dict_compare\u001b[0m:\u001b[36m43\u001b[0m - \u001b[1m    loader_parameters: is_input_dropout: False\u001b[0m\n",
            "\u001b[32m2021-11-18 16:55:56.374\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mivadomed.config_manager\u001b[0m:\u001b[36mdeep_dict_compare\u001b[0m:\u001b[36m43\u001b[0m - \u001b[1m    default_model: is_2d: True\u001b[0m\n",
            "\u001b[32m2021-11-18 16:55:56.374\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mivadomed.config_manager\u001b[0m:\u001b[36m_display_differing_keys\u001b[0m:\u001b[36m152\u001b[0m - \u001b[1m\n",
            "\u001b[0m\n",
            "\u001b[32m2021-11-18 16:55:56.374\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mivadomed.utils\u001b[0m:\u001b[36mget_path_output\u001b[0m:\u001b[36m371\u001b[0m - \u001b[1mCLI flag --path-output not used to specify output directory. Will check config file for directory...\u001b[0m\n",
            "\u001b[32m2021-11-18 16:55:56.374\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mivadomed.utils\u001b[0m:\u001b[36mget_path_data\u001b[0m:\u001b[36m383\u001b[0m - \u001b[1mCLI flag --path-data not used to specify BIDS data directory. Will check config file for directory...\u001b[0m\n",
            "\u001b[32m2021-11-18 16:55:56.374\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mivadomed.main\u001b[0m:\u001b[36mset_output_path\u001b[0m:\u001b[36m198\u001b[0m - \u001b[1mOutput path already exists: spineGeneric_gpu\u001b[0m\n",
            "\u001b[32m2021-11-18 16:55:56.419\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mivadomed.utils\u001b[0m:\u001b[36mdefine_device\u001b[0m:\u001b[36m135\u001b[0m - \u001b[1mUsing GPU ID 0\u001b[0m\n",
            "\u001b[32m2021-11-18 16:55:56.420\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mivadomed.utils\u001b[0m:\u001b[36mdisplay_selected_model_spec\u001b[0m:\u001b[36m145\u001b[0m - \u001b[1mSelected architecture: Unet, with the following parameters:\u001b[0m\n",
            "\u001b[32m2021-11-18 16:55:56.420\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mivadomed.utils\u001b[0m:\u001b[36mdisplay_selected_model_spec\u001b[0m:\u001b[36m148\u001b[0m - \u001b[1m\tdropout_rate: 0.3\u001b[0m\n",
            "\u001b[32m2021-11-18 16:55:56.420\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mivadomed.utils\u001b[0m:\u001b[36mdisplay_selected_model_spec\u001b[0m:\u001b[36m148\u001b[0m - \u001b[1m\tbn_momentum: 0.1\u001b[0m\n",
            "\u001b[32m2021-11-18 16:55:56.420\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mivadomed.utils\u001b[0m:\u001b[36mdisplay_selected_model_spec\u001b[0m:\u001b[36m148\u001b[0m - \u001b[1m\tdepth: 3\u001b[0m\n",
            "\u001b[32m2021-11-18 16:55:56.421\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mivadomed.utils\u001b[0m:\u001b[36mdisplay_selected_model_spec\u001b[0m:\u001b[36m148\u001b[0m - \u001b[1m\tis_2d: True\u001b[0m\n",
            "\u001b[32m2021-11-18 16:55:56.421\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mivadomed.utils\u001b[0m:\u001b[36mdisplay_selected_model_spec\u001b[0m:\u001b[36m148\u001b[0m - \u001b[1m\tfinal_activation: sigmoid\u001b[0m\n",
            "\u001b[32m2021-11-18 16:55:56.421\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mivadomed.utils\u001b[0m:\u001b[36mdisplay_selected_model_spec\u001b[0m:\u001b[36m148\u001b[0m - \u001b[1m\tfolder_name: my_model\u001b[0m\n",
            "\u001b[32m2021-11-18 16:55:56.421\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mivadomed.utils\u001b[0m:\u001b[36mdisplay_selected_model_spec\u001b[0m:\u001b[36m148\u001b[0m - \u001b[1m\tin_channel: 1\u001b[0m\n",
            "\u001b[32m2021-11-18 16:55:56.421\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mivadomed.utils\u001b[0m:\u001b[36mdisplay_selected_model_spec\u001b[0m:\u001b[36m148\u001b[0m - \u001b[1m\tout_channel: 1\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/bids/config.py:40: FutureWarning: Setting 'extension_initial_dot' will be removed in pybids 0.16.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/bids/layout/validation.py:149: UserWarning: The PipelineDescription field was superseded by GeneratedBy in BIDS 1.4.0. You can use ``pybids upgrade`` to update your derivative dataset.\n",
            "  warnings.warn(\"The PipelineDescription field was superseded \"\n",
            "\u001b[32m2021-11-18 16:55:57.748\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mivadomed.loader.bids_dataframe\u001b[0m:\u001b[36msave\u001b[0m:\u001b[36m289\u001b[0m - \u001b[1mDataframe has been saved in spineGeneric_gpu/bids_dataframe.csv.\u001b[0m\n",
            "\u001b[32m2021-11-18 16:55:57.752\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mivadomed.loader.utils\u001b[0m:\u001b[36msplit_dataset\u001b[0m:\u001b[36m102\u001b[0m - \u001b[33m\u001b[1mAfter splitting: train, validation and test fractions are respectively 0.6, 0.2 and 0.2 of participant_id.\u001b[0m\n",
            "\u001b[32m2021-11-18 16:55:58.701\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mivadomed.utils\u001b[0m:\u001b[36mdisplay_selected_transfoms\u001b[0m:\u001b[36m158\u001b[0m - \u001b[1mSelected transformations for the ['testing'] dataset:\u001b[0m\n",
            "\u001b[32m2021-11-18 16:55:58.701\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mivadomed.utils\u001b[0m:\u001b[36mdisplay_selected_transfoms\u001b[0m:\u001b[36m160\u001b[0m - \u001b[1m\tResample: {'hspace': 0.75, 'wspace': 0.75, 'dspace': 1}\u001b[0m\n",
            "\u001b[32m2021-11-18 16:55:58.702\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mivadomed.utils\u001b[0m:\u001b[36mdisplay_selected_transfoms\u001b[0m:\u001b[36m160\u001b[0m - \u001b[1m\tCenterCrop: {'size': [128, 128]}\u001b[0m\n",
            "\u001b[32m2021-11-18 16:55:58.702\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mivadomed.utils\u001b[0m:\u001b[36mdisplay_selected_transfoms\u001b[0m:\u001b[36m160\u001b[0m - \u001b[1m\tNormalizeInstance: {'applied_to': ['im']}\u001b[0m\n",
            "Loading dataset: 100% 6/6 [00:00<00:00, 161.52it/s]\n",
            "\u001b[32m2021-11-18 16:56:05.540\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mivadomed.loader.loader\u001b[0m:\u001b[36mload_dataset\u001b[0m:\u001b[36m114\u001b[0m - \u001b[1mLoaded 94 axial slices for the testing set.\u001b[0m\n",
            "\u001b[32m2021-11-18 16:56:05.541\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mivadomed.testing\u001b[0m:\u001b[36mtest\u001b[0m:\u001b[36m51\u001b[0m - \u001b[1mLoading model: spineGeneric_gpu/best_model.pt\u001b[0m\n",
            "Inference - Iteration 0: 100% 6/6 [00:14<00:00,  2.44s/it]\n",
            "\u001b[32m2021-11-18 16:56:35.045\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mivadomed.testing\u001b[0m:\u001b[36mtest\u001b[0m:\u001b[36m87\u001b[0m - \u001b[1m{'dice_score': 0.9090897621830837, 'multi_class_dice_score': 0.9090897621830837, 'precision_score': 0.8584016858957487, 'recall_score': 0.9689729883662824, 'specificity_score': 0.9997912595822612, 'intersection_over_union': 0.8348760781023308, 'accuracy_score': 0.9997505841734929, 'hausdorff_score': 0.0674809834038413}\u001b[0m\n",
            "\u001b[32m2021-11-18 16:56:35.052\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mivadomed.evaluation\u001b[0m:\u001b[36mevaluate\u001b[0m:\u001b[36m33\u001b[0m - \u001b[1m\n",
            "Run Evaluation on spineGeneric_gpu/pred_masks\n",
            "\u001b[0m\n",
            "Evaluation: 100% 6/6 [00:07<00:00,  1.26s/it]\n",
            "\u001b[32m2021-11-18 16:56:42.601\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mivadomed.evaluation\u001b[0m:\u001b[36mevaluate\u001b[0m:\u001b[36m113\u001b[0m - \u001b[1m                     avd_class0  ...  vol_pred_class0\n",
            "image_id                         ...                 \n",
            "sub-unf01_T1w          0.035910  ...      6382.499391\n",
            "sub-unf01_T2w          0.075269  ...      6624.999368\n",
            "sub-mpicbs06_T2star    0.316078  ...      6006.249427\n",
            "sub-mpicbs06_T2w       0.148635  ...      5573.749468\n",
            "sub-unf01_T2star       0.137438  ...      6558.749375\n",
            "\n",
            "[5 rows x 16 columns]\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "# @title Run me to test the model!\n",
        "\n",
        "# test the model\n",
        "!ivadomed --test -c config.json"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fnwz7It8BACM",
        "outputId": "4006eb91-0fd0-47a8-d022-6626eb28089e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Zip file created!\n"
          ]
        }
      ],
      "source": [
        "# @title Save the results in a zip file!\n",
        "# @markdown Now that training and testing are done, we would like to download\n",
        "# @markdown the results locally for further anaylsis. For that, we first\n",
        "# @markdown create a `.zip` file of the results folder and then download\n",
        "# @markdown the zipped file manually. \n",
        "\n",
        "# first, zip the results folder\n",
        "!zip -r --quiet spineGeneric_gpu.zip spineGeneric_gpu/\n",
        "print(\"Zip file created!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_ye2RNLip-ci"
      },
      "source": [
        "Now, check out the Files tab on the right. You can find spineGeneric_gpu.zip when you refresh the content (see the top bar) and then download the zip file to your browser's standard Downloads folder."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gGRw-LtivjaP"
      },
      "source": [
        "The test image segmentations are stored in `<PATH_TO_OUT_DIR>/pred_masks/` and have the same name as the input image with the suffix `_pred`. To visualize the segmentation of a given subject, you can use any Nifti image viewer (e.g. [ITK-SNAP](http://www.itksnap.org/pmwiki/pmwiki.php), [FSLeyes](https://open.win.ox.ac.uk/pages/fsl/fsleyes/fsleyes/userdoc/)). "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A69EXdJeGIwT"
      },
      "source": [
        "After the training for 100 epochs, the segmentations should be similar to the one presented in the following image. The output and ground truth segmentations of the spinal cord are presented in red (subject `sub-mpicbs06` with contrast T2w):\n",
        "\n",
        "<img src=\"https://raw.githubusercontent.com/ivadomed/doc-figures/main/tutorials/one_class_segmentation_2d_unet/sc_prediction.png\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RygQLOgBHTs_"
      },
      "source": [
        "‚ö†Ô∏è **Note**: In case you prefer running things on the terminal instead of notebooks, ivadomed also makes that possible. Head over to [this](https://ivadomed.org/tutorials/one_class_segmentation_2d_unet.html) page that explains this tutorial from the terminal. However, before doing that please ensure that you have installed `ivadomed` locally. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uDco238GHHti"
      },
      "source": [
        "So, that was it for the first tutorial! We saw a simple example of how `ivadomed` can be used to segment the spinal cord. Please try the other tutorials to get a better feel of what `ivadomed` has to offer. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A6M5V1XwBAFL"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "ivadomed_tutorial-1_2d-segmentation-unet.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
